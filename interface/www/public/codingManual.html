<h3 class="mb-4">Coding Manual</h3>
<p>This manual describes the evidence we are looking for in each question of the evidence extraction form. Reference these descriptions for clarification and consistency as needed.

<div id="studyContextCodingManual">
<h4 class="mb-3">Study Context</h4>
<div id="studyContext_1_manual">
<p class="mb-n1">1. What kind of study is this? 
<i class="fa fa-lg fa-pencil-square ml-3" title="Evidence Extraction" target="studyContext_1_extraction"/>
<div class="codingManualDiv">
<p><b><u>Description</u></b>: We differentiate kinds of studies depending on the degree of control the authors exert on the situation under study. In experiments, the authors may <a href="https://en.wikipedia.org/wiki/Random_assignment">assign</a> participants to treatment and control groups and attempt to isolate the effect they are measuring through <a href="https://onlinelibrary.wiley.com/doi/pdf/10.1002/9780470479216.corpsy0332">experimental control</a>. In observational studies, the authors measure the situation under study in the real-world without exerting their influence.
 In most observational studies, there should still be a control group whose experience reflects the absence of the intervention or treatment of interest without <a href="https://en.wikipedia.org/wiki/Random_assignment">random assignment.</a> 
<p><b><u>Location</u></b>: Articles will often explicitly state what kind of study was run, usually in the Method section. 
<p><b><u>Importance</u></b>: When comparing studies, we will want to consider whether different kinds of studies yield different patterns of results.
</div></div>
<br>
<div id="studyContext_setting_manual">
<p class="mb-n1">4. What was the study setting?
<i class="fa fa-lg fa-pencil-square ml-3" title="Evidence Extraction" target="studyContext_setting_extraction"/>
<div class="codingManualDiv">
<p><b><u>Description</u></b>: Studies present data gathered in different kinds of settings or environments. A controlled setting is one in which the authors have attempted to isolate the effect of interest by eliminating factors that might exist in real-world situations. In contrast, a naturalistic setting is one in which the authors have exerted no influence and are taking measurements in the real world. A crowdsourced setting is one in which data is collected online. 
<p><b><u>Location</u></b>: Study settings will often align with the kind of study and should be reported in the Method section. 
<p><b><u>Importance</u></b>: When comparing studies, we will want to consider whether different settings yield different patterns of results.
</div></div>

<br>
<h4 class="mb-3" id="participantsCodingManual">Participants</h4>
<div id="participants_1_manual">
<p class="mb-n1">1. Briefly describe the process used to recruit participants for the study.
<i class="fa fa-lg fa-pencil-square ml-3" title="Evidence Extraction" target="participants_1_extraction"/>
<div class="codingManualDiv">
<p><b><u>Description</u></b>: We think of participants in studies as being <a href="https://www.statisticshowto.datasciencecentral.com/what-is-a-population/">sampled</a> from a particular population. Populations are essentially groups defined by common characteristics. If the recruitment process in a study biases the sample to include or omit a particular kind of participant (i.e., <a href="https://en.wikipedia.org/wiki/Selection_bias">selection bias</a>), we want to document this information so we can reason about the population in the study. 
<p><b><u>Location</u></b>: Information about the recruitment process will often be reported in the Method section.
<p><b><u>Importance</u></b>: The effect we are interested in might be different in different populations, so we will want to consider whether the studies we plan to combine are sampling such different populations that it doesn't make sense to aggregate their results in a meta-analysis.
</div></div>
<br>
<div id="participants_2_manual">
<p class="mb-n1">2. List any inclusion or exclusion criteria that were used to filter out participants in the study.
<i class="fa fa-lg fa-pencil-square ml-3" title="Evidence Extraction" target="participants_2_extraction"/>
<div class="codingManualDiv">
<p><b><u>Description</u></b>: We think of participants in studies as being <a href="https://www.statisticshowto.datasciencecentral.com/what-is-a-population/">sampled</a> from a particular population. Populations are essentially groups defined by common characteristics. If a study excludes participants in a way that biases the sample to omit a particular kind of participant (i.e., <a href="https://en.wikipedia.org/wiki/Selection_bias">selection bias</a>), we want to document this information so we can reason about the population in the study.
<p><b><u>Location</u></b>: Information about exclusions will often be reported in the Method or Results section.
<p><b><u>Importance</u></b>: The effect we are interested in might be different in different populations, so we will want to consider whether the studies we plan to combine are sampling such different populations that it doesn't make sense to aggregate their results in a meta-analysis.
</div></div>
<br>
<div id="participants_3_manual">
<p class="mb-n1">3. Briefly describe the <b>final sample of participants</b> after the recruitment and exclusion processes in terms of relevant characteristics (e.g., demographics, occupation, health status). These are the people whose data are reflected in the results of the study.
<i class="fa fa-lg fa-pencil-square ml-3" title="Evidence Extraction" target="participants_3_extraction"/>
<div class="codingManualDiv">
<p><b><u>Description</u></b>: We want to document any characteristics reported about the final sample of participants that help us reason about the population they represent. This might be evidence that the sample is <a href="https://www.statisticssolutions.com/what-is-a-representative-sample/">representative</a> of the population we want to make an inference about or that the sample is not representative in some way.
<p><b><u>Location</u></b>: Information about study participants will often be reported in the Methods or Results section.
<p><b><u>Importance</u></b>:  If the study participants are too different from the participants in other studies, it may not make sense to combine the results of these studies in a meta-analysis. If the study participants are too different from the population we are interested in making inferences about, the results from this study may not be applicable or relevant to our meta-analysis.
</div></div>


<br>
<h4 class="mb-3" id="measurementCodingManual">Measurement</h4>
<div id="measurement_2_manual">
<p class="mb-n1">2. How was the independent variable defined? Briefly describe how the author(s) implement the intervention and control conditions in the study.
<i class="fa fa-lg fa-pencil-square ml-3" title="Evidence Extraction" target="measurement_2_extraction"/>
<div class="codingManualDiv"> 
<p><b><u>Description</u></b>: Studies typically measure the effect of some manipulation or intervention. The specific condition which is manipulated is called an <a href="https://www.simplypsychology.org/variables.html">independent variable</a>. An independent variable is assumed to have an impact on the outcome of interest (i.e., <a href="https://www.simplypsychology.org/variables.html">dependent variable</a>).
<p><b><u>Location</u></b>:  Independent variables will often be mentioned throughout the paper but in particular in the Method and Results section
<p><b><u>Importance</u></b>: When conducting a meta-analysis, we will want to make sure that each of the studies we include measure the impact of the same independent variable. Otherwise, it doesnï¿½t make sense to compare them. We also want to make sure that the manipulation of the independent variable produces conditions similar to the situation we are trying to make an inference about.
</div></div>

<br>
<div id="measurement_4_manual">
<p class="mb-n1">4. Was the intervention given to participants in the study for a specific duration or in a certain dose?
<i class="fa fa-lg fa-pencil-square ml-3" title="Evidence Extraction" target="measurement_4_extraction"/>
<div class="codingManualDiv"> 
<p><b><u>Description</u></b>: The duration or dose of intervention indicates the degree of exposure to the intervention of interest. For example, the intervention could be a training program that lasts two weeks, or it could be a drug that the participant receives a certain amount of. Study authors may choose the degree of exposure to intervention in order to maximize their ability to detect the effect of intervention, to accommodate concerns about what is safe or feasible, or for other motivations.
<p><b><u>Location</u></b>: This information should be reported in the Method or Results section.
<p><b><u>Importance</u></b>: In order to compare results across studies, we want to know that exposure to the intervention of interest was similar across studies in our review. If the duration or dose of intervention varies too much across studies in the review, it may not make sense to average effect size estimates together in a meta-analysis without somehow adjusting for the effect of different durations or doses.
</div></div>

<br>
<div id="measurement_5_manual">
<p class="mb-n1">5. How was the dependent variable defined? Briefly describe how the author(s) measure or observe the outcome of interest in the study.
<i class="fa fa-lg fa-pencil-square ml-3" title="Evidence Extraction" target="measurement_5_extraction"/>
<div class="codingManualDiv"> 
<p><b><u>Description</u></b>: The dependent variable is how the authors measured the outcome of interest. This question asks what was actually done to get the measurements reported in the paper, and what set of conditions needed to be met in order for the authors to measure the outcome of interest. For example, the authors may have administered a survey, brought participants into the lab for data collection, or retrieved data that had already been collected for another study. In choosing how to collect measurements, the authors may qualify or limit what counts as an instance of the outcome of interest within the scope of their research.
<p><b><u>Location</u></b>: This information should be reported in the Method or Results section.
<p><b><u>Importance</u></b>: In order to compare results across studies, we want to know where the data came from and whether or not studies differ in their methods of measurement.
</div></div>

<br>
<div id="measurement_6_manual">
<p class="mb-n1">6. Please categorize the outcome of interest as one of the following?
<i class="fa fa-lg fa-pencil-square ml-3" title="Evidence Extraction" target="measurement_6_extraction"/>
<div class="codingManualDiv"> 
<p><b><u>Description</u></b>: This question asks about the data type of the outcome of interest. Studies with a dichotomous outcome often measure the rate of occurrence of some event (e.g., death, diagnosis, employment, etc.) and how the intervention of interest impacts this rate. In contrast, studies with a continuous outcome often seek to quantify the change in some scale or indicatory in response to the intervention of interest.
<p><b><u>Location</u></b>: This information should be reported in the Method or Results section.
<p><b><u>Importance</u></b>: Whether the outcome of interest is dichotomous or continuous determines what information we need to extract from the article in order to calculate the <a href="https://www.theanalysisfactor.com/two-types-effect-size-statistic/">standardized effect size</a>.
</div></div>

<br>
<div id="measurement_7_manual">
<p class="mb-n1">7. Were the outcome measurements for the intervention and control conditions compared <b>between-subjects</b>, 
	such that each participant either in the intervention or the control condition, or <b>within-subjects</b>, 
	such that each participant was in both the intervention or the control conditions at different times?
<i class="fa fa-lg fa-pencil-square ml-3" title="Evidence Extraction" target="measurement_7_extraction"/>
<div class="codingManualDiv"> 
<p><b><u>Description</u></b>: Some studies involve <a href="https://en.wikipedia.org/wiki/Longitudinal_study">repeated measurements</a> from the same individual participants over time. For example, authors may administer a survey to the same person at multiple points in time to compare outcomes with and without an intervention or to
	 <a href="https://www.statisticssolutions.com/the-power-advantage-of-within-subjects-designs/">improve statistical power</a> of their study design. These within-subjects measurements are in contrast with between-subjects measurements.
<p><b><u>Location</u></b>:  Whether a measurement is within- or between-subjects will be reported in the Method or Results section.
<p><b><u>Importance</u></b>: Whether measurements are taken within- or between-subjects is important to consider when deciding whether to aggregate studies in meta-analysis. It is best practice not to combine within-subjects studies with between-subjects studies since these approaches are thought to measure different things.
</div></div>

<br>
<div id="measurement_8_manual">
<p class="mb-n1">8. What was the time schedule for measurement in the study? When were measures taken?
<i class="fa fa-lg fa-pencil-square ml-3" title="Evidence Extraction" target="measurement_8_extraction"/>
<div class="codingManualDiv">
<p><b><u>Description</u></b>: Some study authors may <a href="https://asq.org/quality-resources/stratification">stratify</a> their data based on time. For example, they may report a measure taken at different durations after an intervention or baseline event. When authors stratify their data by time, it is often because the timing of events is important to their research question or the domain of study.
<p><b><u>Location</u></b>: The timing of measurements will be reported in the Method or Results section. 
<p><b><u>Importance</u></b>: To the extent that the time course of measurements vary across studies, this may be important to consider when deciding whether to aggregate studies in meta-analysis. If the timing of measurements is dissimilar across studies, combining them in a meta-analysis will yield a result that averages over different time courses of measurement. At best this adds noise to the analysis; at worst it obfuscates the meaning of the aggregated effect size (e.g., if the effect is thought to change over time).
</div></div>
<br>
<div id="measurement_9_manual">
<p class="mb-n1">9. Do the authors report this measure separately for different groups of participants (e.g., grouping their sample by demographics or some other factor)?
<i class="fa fa-lg fa-pencil-square ml-3" title="Evidence Extraction" target="measurement_9_extraction"/>
<div class="codingManualDiv">
<p><b><u>Description</u></b>: Study authors may group or <a href="https://asq.org/quality-resources/stratification">stratify</a> their participants (e.g., by gender or age) and report effects within each group (e.g., presenting results in <a href="https://humansofdata.atlan.com/2016/01/cross-tabulation-how-why/">contingency tables</a>). Authors create these groups by identifying factors or variables which are of interest in their analysis. Each of these factors has different levels or possible values it might take on. For example, for the categorical factor of gender, possible levels might be man, woman, or non-binary. For continuous factors like age, the study authors might create levels by <a href="https://en.wikipedia.org/wiki/Data_binning">binning</a> their data into relevant age groups (e.g., 18-30, 30-50, 50-65, 65+) as a way of forming discrete levels. When authors present results for different groups, it is often because those grouping factors are thought to influence the effect of interest.
<p><b><u>Location</u></b>: Grouping factors should be reported in the Results section, but the rationale for their importance may be located elsewhere or may not be explicitly stated.
<p><b><u>Importance</u></b>: We need to decide whether these grouping factors are of interest for meta-analysis, or if we prefer to only document the overall effect. Even if we are interested in group-level effects, we will only be able to include them in our meta-analysis if they are reported across multiple studies.
</div></div>
<br>

<h4 class="mb-3" id="effectSizeCodingManual">Effect Size</h4>
<p>Please use the following items to capture, in as much detail as possible, information reported about estimates of <a href="https://www.statisticssolutions.com/statistical-analyses-effect-size/">effect size</a>. You will almost certainly find this information in the Results section. For each statistic reported about the effect of interest, please fill out the following items.
<div id="effectSize_4_manual">
<p class="mb-n1"><span class="number">3</span>. How do the authors report the reliability of the estimated difference between the intervention and control groups? Please check one of the following.
<i class="fa fa-lg fa-pencil-square ml-3" title="Evidence Extraction" target="effectSize_4_extraction"/>
<div class="codingManualDiv">
<p><b><u>Description</u></b>: Reliability is an indicator of how repeatable the estimation process is. Reliability statistics answer the question: How likely is it that if we repeated the same analysis process, it would produce a similar effect size estimate? Reliability might be reported as a test statistic such as a <a href="https://www.statisticshowto.datasciencecentral.com/probability-and-statistics/t-test/">t-test</a> or an <a href="https://blog.minitab.com/blog/adventures-in-statistics-2/understanding-analysis-of-variance-anova-and-the-f-test">ANOVA F-test</a>. Alternatively, it might be a <a href="https://blog.minitab.com/blog/adventures-in-statistics-2/how-to-correctly-interpret-p-values">p-value</a>, a <a href="https://www.sas.upenn.edu/~allison/Oct8.pdf">standard error</a>, or a <a href="http://mathbootcamps.com/interpreting-confidence-intervals/">confidence interval</a>. 
<p><b><u>Location</u></b>: Reliability should be reported in the Results section alongside the effect size estimate.
<p><b><u>Importance</u></b>: We want to document reliability information so that we know how uncertain the results from the study are. We need to incorporate this error into our meta-analysis.
</div></div>

<br>
<div class="mb-n1" id="effectSize_6_manual"><span class="number">6</span>. If the study authors adjusted their effect size estimate for <a href="https://www.statisticshowto.datasciencecentral.com/covariate/">covariates</a>, 
     either by <a href="https://www.alleydog.com/glossary/definition.php?term=Matched+Group+Design">matching intervention and control groups</a> on 
     confounding variables or by <a href="https://stats.stackexchange.com/questions/3944/explain-model-adjustment-in-plain-english">including covariates in a statistical model</a>,
      what covariates did they adjust for? Please check any of the following that apply, and add any variables in the adjustment set that are not already listed below.
<i class="fa fa-lg fa-pencil-square ml-3" title="Evidence Extraction" target="effectSize_6_extraction"/>
<div class="codingManualDiv">
<p><b><u>Description</u></b>: Covariates are variables other than the predictor and outcome of interest which are included in a statistical model. Including these other variables in the model adjusts the effect size estimate for the influence of these covariates. Specifically, the model splits the data into groups for each level of the covariates, calculates the effect of interest in each group, and takes a weighted average of the effect size across these groups. Covariates might be demographic variables like age or characteristics like health status which impact both the predictor and the outcome of interest. Most regression models in particular will have covariates, but other kinds of models may not. 
<p><b><u>Location</u></b>: The authors should report covariates for each model in their Methods or Results. 
<p><b><u>Importance</u></b>: Studies adjusting for different sets of covariates will estimate different effect sizes. It is best practice not to combine effects which are adjusted for different sets of covariates.
</div></div>

<h4 class="mb-3" id="riskOfBiasCodingManual">Risk of Bias</h4>
<p>Please use these questions to gage how well the study was conducted (i.e., internal validity). The subsections below reflect various threats to validity which could undermine the fidelity of effect size estimates.

<h5 class="mb-3" id="selectionBiasCodingManual">Selection Bias</h5>
<div class="mb-n1" id="selectionBias_1_manual">1. Did the study fail to randomly assign participants to intervention and control conditions?
     <i>This could be an issue if, for example:
	 <ul>
	 <li>The authors did not use a random or pseudo-random process for group assignment.</li>
	 <li>The assignment process was predictable to participants or study personnel.</li>
	 <li>The study was not an experiment.</li>
	 </ul>
	 </i>
</div>
<div class="mb-n1" id="selectionBias_2_manual">2. Did exclusion or attrition result in intervention and control groups that were systematically different?
     <i>This could be an issue if, for example:
	 <ul>
	 <li>Participants who withdrew from the study were systematically different from the final sample of participants.</li>
	 <li>Participants who were excluded from the study were systematically different from the final sample of participants.</li>
	 <li>The study authors handled missing data in a way that relied on strong and potentially unreasonable assumptions (e.g., an unreasonable <a href="https://en.wikipedia.org/wiki/Imputation_(statistics)">imputation</a> strategy).</li>
	 </ul>
	 </i>
</div>
<div class="mb-n1" id="selectionBias_3_manual">3. Did the study fail to control for <a href="https://en.wikipedia.org/wiki/Confounding">confounding</a> variables that could explain differences in the outcome of interest between the intervention and control groups?
	 <i>This could be an issue if, for example:
	 <ul>
	 <li>The authors failed to measure known confounding variables.</li>
	 <li>Potentially confounding variables were differently distributed within the intervention and control groups.</li>
	 <li>The study authors did not control for known confounding variables by either 
	 <a href="https://www.alleydog.com/glossary/definition.php?term=Matched+Group+Design">matching the study groups on them</a> or 
	 <a href="https://stats.stackexchange.com/questions/3944/explain-model-adjustment-in-plain-english">using them as covariates</a> in a regression model</li>
	 <li>The study authors attempted to control for a variable that was <b>not</b> a confounding factor in the intervention-outcome relationship 
	 (e.g., by <a href="https://stats.stackexchange.com/questions/19613/overmatching-bias-and-confounding-variables">overmatching</a> or including a 
	 <a href="https://en.wikipedia.org/wiki/Collider_(statistics)">collider</a> in their regression model).</li>
	 </ul>
	 </i>
</div>

<h5 class="mb-3" id="measurementIssuesCodingManual">Measurement Issues</h5>
<div id="measurementIssues_1_manual">1. Did the study fail to isolate the impact of being in the intervention versus control group?
	 <i>This could be an issue if, for example:
	 <ul>
	 <li>Participants didn't stay in the group they were assigned to (e.g., by not adhering to a treatment schedule).</li>
	 <li>The procedure for determining membership in the intervention and control groups involved a subjective judgment on the part of study personnel.</li>
	 <li>The procedure for determining membership in the intervention and control groups involved unverified recall and/or self-report on the part of the participant.</li>
	 <li>Study personnel were not blind to group membership and treated participants differently depending on whether they were in the intervention or control condition.</li>
	 <li>Participants were not blind to group membership and changed their behavior to satisfy the expectations of study personnel.</li>
	 </ul>
	 </i>
</div>
<div id="measurementIssues_2_manual">2. Did the study fail to detect or measure the outcome of interest?
	 <i>This could be an issue if, for example:
	 <ul>
	 <li>Different procedures were used for measuring the outcome of interest in the intervention and control groups, respectively.</li>
	 <li>The procedure for measuring the outcome of interest involved a subjective judgment on the part of study personnel.</li>
	 <li>The procedure for measuring the outcome of interest involved unverified recall and/or self-report on the part of the participant.</li>
	 <li>The outcome of interest was already present at the start of the study (e.g., participants in a study on weight loss were already at a healthy weight).</li>
	 <li>The follow-up period in which measurements were made was not long enough to allow the outcome of interest to occur (e.g., a study of cancer risk that only measures the presence of cancer for two months after intervention).</li>
	 <li>Participants were previously exposed to conditions that would impact the outcome of interest.</li>
	 </ul>
	 </i>
</div>

<h5 class="mb-3" id="reportingBiasCodingManual">Reporting Bias</h5>
<div id="reportingBias_1_manual">1. Did the study authors seem to selectively report findings to support a particular narrative?
	 <i>This could be an issue if, for example:
	 <ul>
	 <li>Not all outcomes described in the study's methods were reported in the results.</li>
	 <li>The study was funded or run by an entity that has an incentive to report a particular result.</li>
	 <li>The authors did not adequately describe their procedures for data collection and analysis such that an independent party to reproduce them.</li>
	 <li>The study authors seem to have stopped data collection early for benefit (e.g., once they obtained a statistically significant result).</li>
	 </ul>
	 </i>
</div>

<h4 class="mb-3" id="applicabilityCodingManual">Applicability</h4>
<i><p>Please use these questions to gage how well the study applies to the situation about which you are trying to make an inference (i.e., external validity). The subjections below reflect various concerns which could limit the generalizability of the study findings.
</i>
<div id="applicability_5_manual">5. Was the outcome measured in this study different in important ways from the outcome you are interested in making an inference about?
	 <i>This might be an issue if, for example:
	 <ul>
	 <li>The follow-up duration in which outcomes were measured was not similar to the timeframe about which you are interested in making an inference.</li>
	 <li>The study measured an outcome which was not of practical importance but was thought to be a proxy for the outcome of interest.</li>
	 </ul>
	 </i>
</div>

</div>  
</div>
